{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-26T02:23:21.148726800Z",
     "start_time": "2024-07-26T02:23:17.010864700Z"
    }
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "class Lang:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {0:\"SOS\",1:\"EOS\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addSentence(self,sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T02:41:24.075395700Z",
     "start_time": "2024-07-26T02:41:24.066213100Z"
    }
   },
   "id": "f6e4b96dfb07ae97",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "name = \"eng\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T02:42:59.608205400Z",
     "start_time": "2024-07-26T02:42:59.591796300Z"
    }
   },
   "id": "a69dfe86abd97a9f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sentence = \"hello I am Jay\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T02:43:16.741732400Z",
     "start_time": "2024-07-26T02:43:16.725756200Z"
    }
   },
   "id": "9c9486352bb42c57",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2index: {'hello': 2, 'I': 3, 'am': 4, 'Jay': 5}\n",
      "index2word: {0: 'SOS', 1: 'EOS', 2: 'hello', 3: 'I', 4: 'am', 5: 'Jay'}\n",
      "n_words: 6\n"
     ]
    }
   ],
   "source": [
    "eng1 = Lang(name)\n",
    "eng1.addSentence(sentence)\n",
    "print(\"word2index:\",eng1.word2index)\n",
    "print(\"index2word:\",eng1.index2word)\n",
    "print(\"n_words:\",eng1.n_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T02:49:22.975477300Z",
     "start_time": "2024-07-26T02:49:22.925746600Z"
    }
   },
   "id": "5bd034fd32d0c468",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD',s)\n",
    "        if unicodedata.category(c)!= 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([ .!?])\",r\" \\1\",s)\n",
    "    s = re.sub(r\"[^a-zA.!?]+\",r\" \",s)\n",
    "    return s"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T02:58:00.006933500Z",
     "start_time": "2024-07-26T02:57:59.983479300Z"
    }
   },
   "id": "8e7ccaefc071fa61",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "s = \"Are you kidding me?\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T02:58:51.512301700Z",
     "start_time": "2024-07-26T02:58:51.502789600Z"
    }
   },
   "id": "b091a1269169c8da",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you kidding me ?\n"
     ]
    }
   ],
   "source": [
    "nsr = normalizeString(s)\n",
    "print(nsr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T02:58:52.040279300Z",
     "start_time": "2024-07-26T02:58:52.030560500Z"
    }
   },
   "id": "3ad2626f73be2032",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_path = 'data/eng-fra.txt'\n",
    "\n",
    "def readLangs(lang1,lang2):\n",
    "    lines = open(data_path,encoding='utf-8').read().strip('').split('\\n')\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "    return input_lang,output_lang,pairs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:06:38.008525Z",
     "start_time": "2024-07-26T03:06:37.979964700Z"
    }
   },
   "id": "fea1f3ab3de475f6",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lang1 = \"eng\"\n",
    "lang2 = \"fra\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:06:38.851305100Z",
     "start_time": "2024-07-26T03:06:38.841633900Z"
    }
   },
   "id": "d13c1bd38015fc08",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_lang: <__main__.Lang object at 0x00000220A1A82500>\n",
      "output_lang: <__main__.Lang object at 0x00000220A1B0B940>\n",
      "pairs中的前五个: [['go .', 'va !'], ['run !', 'cours !'], ['run !', 'courez !'], ['wow !', 'ca alors !'], ['fire !', 'au feu !']]\n"
     ]
    }
   ],
   "source": [
    "input_lang,output_lang,pairs = readLangs(lang1,lang2)\n",
    "print(\"input_lang:\",input_lang)\n",
    "print(\"output_lang:\",output_lang)\n",
    "print(\"pairs中的前五个:\",pairs[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:06:44.545095300Z",
     "start_time": "2024-07-26T03:06:39.377693800Z"
    }
   },
   "id": "2a9ebf3fc790c81",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 设置组成句子中单词或标点的最多个数\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "# 选择带有指定前缀的语言特征数据作为训练数据\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    \"\"\"语言对过滤函数, 参数p代表输入的语言对, 如['she is afraid.', 'elle malade.']\"\"\"\n",
    "    # p[0]代表英语句子，对它进行划分，它的长度应小于最大长度MAX_LENGTH并且要以指定的前缀开头\n",
    "    # p[1]代表法文句子, 对它进行划分，它的长度应小于最大长度MAX_LENGTH\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        p[0].startswith(eng_prefixes) and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    \"\"\"对多个语言对列表进行过滤, 参数pairs代表语言对组成的列表, 简称语言对列表\"\"\"\n",
    "    # 函数中直接遍历列表中的每个语言对并调用filterPair即可\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:11:19.423733800Z",
     "start_time": "2024-07-26T03:11:19.406445600Z"
    }
   },
   "id": "158bcc10b095bdfc",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过滤后的pairs前五个: [['i m .', 'j ai ans .'], ['i m ok .', 'je vais bien .'], ['i m ok .', 'ca va .'], ['i m fat .', 'je suis gras .'], ['i m fat .', 'je suis gros .']]\n"
     ]
    }
   ],
   "source": [
    "fpairs = filterPairs(pairs)\n",
    "print(\"过滤后的pairs前五个:\",fpairs[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:12:39.430632100Z",
     "start_time": "2024-07-26T03:12:39.329731100Z"
    }
   },
   "id": "5ac38041582a251e",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prepareData(lang1,lang2):\n",
    "    input_lang,output_lang,pairs = readLangs(lang1,lang2)\n",
    "    pairs = filterPairs(pairs)\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    return input_lang,output_lang,pairs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:21:17.291173100Z",
     "start_time": "2024-07-26T03:21:17.266359900Z"
    }
   },
   "id": "7b60bfb9cb62a401",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_n_words: 2803\n",
      "output_n_words: 4345\n",
      "['you re famous .', 'vous etes connues .']\n"
     ]
    }
   ],
   "source": [
    "input_lang,output_lang,pairs = prepareData('eng','fra')\n",
    "print(\"input_n_words:\",input_lang.n_words)\n",
    "print(\"output_n_words:\",output_lang.n_words)\n",
    "print(random.choice(pairs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:21:22.932976500Z",
     "start_time": "2024-07-26T03:21:17.859635500Z"
    }
   },
   "id": "db59b5142790a75f",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tensorFromSentence(lang,sentence):\n",
    "    indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes,dtype=torch.long,device=device).view(-1,1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang,pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang,pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:31:14.778086200Z",
     "start_time": "2024-07-26T03:31:14.749478900Z"
    }
   },
   "id": "8f6a74bb6a244930",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pair = pairs[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:31:15.350605500Z",
     "start_time": "2024-07-26T03:31:15.325766300Z"
    }
   },
   "id": "9c70bdbc18b5f05",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [1]]), tensor([[2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [1]]))\n"
     ]
    }
   ],
   "source": [
    "pair_tensor = tensorsFromPair(pair)\n",
    "print(pair_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T03:31:15.736636400Z",
     "start_time": "2024-07-26T03:31:15.719528800Z"
    }
   },
   "id": "f598db88c65a0a44",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size,hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size,hidden_size)\n",
    "    def forward(self,input,hidden):\n",
    "        output = self.embedding(input).view(1,1,-1)\n",
    "        output,hidden = self.gru(output,hidden)\n",
    "        return output,hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1,self.hidden_size,device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T04:02:59.484681600Z",
     "start_time": "2024-07-26T04:02:59.469157Z"
    }
   },
   "id": "3fbe18a629a86299",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hidden_size = 25\n",
    "input_size = 20"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T04:08:12.966882700Z",
     "start_time": "2024-07-26T04:08:12.940101200Z"
    }
   },
   "id": "755fc5d316abfd36",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input = pair_tensor[0][0]\n",
    "hidden = torch.zeros(1,1,hidden_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T04:09:41.964765700Z",
     "start_time": "2024-07-26T04:09:41.938673300Z"
    }
   },
   "id": "21cb1b6de27564ac",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0875,  0.2275,  0.3158,  0.1524, -0.0161,  0.4770,  0.0928,\n",
      "          -0.2908,  0.1779, -0.2832, -0.0481, -0.0850,  0.2756,  0.4541,\n",
      "           0.4902, -0.5181, -0.0529,  0.0989, -0.3224, -0.0979, -0.3937,\n",
      "          -0.0367,  0.2421, -0.4825,  0.2413]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(input_size,hidden_size)\n",
    "encoder_output,hidden = encoder(input,hidden)\n",
    "print(encoder_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T04:10:32.285314200Z",
     "start_time": "2024-07-26T04:10:32.197696200Z"
    }
   },
   "id": "7875e32151a5cb7c",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        \"\"\"初始化函数有两个参数，hidden_size代表解码器中GRU的输入尺寸，也是它的隐层节点数\n",
    "           output_size代表整个解码器的输出尺寸, 也是我们希望得到的指定尺寸即目标语言的词表大小\"\"\"\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # 将hidden_size传入到类中\n",
    "        self.hidden_size = hidden_size\n",
    "        # 实例化一个nn中的Embedding层对象, 它的参数output这里表示目标语言的词表大小\n",
    "        # hidden_size表示目标语言的词嵌入维度\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # 实例化GRU对象，输入参数都是hidden_size，代表它的输入尺寸和隐层节点数相同\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # 实例化线性层, 对GRU的输出做线性变化, 获我们希望的输出尺寸output_size\n",
    "        # 因此它的两个参数分别是hidden_size, output_size\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        # 最后使用softmax进行处理，以便于分类\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"解码器的前向逻辑函数中, 参数有两个, input代表目标语言的Embedding层输入张量\n",
    "           hidden代表解码器GRU的初始隐层张量\"\"\"\n",
    "        # 将输入张量进行embedding操作, 并使其形状变为(1,1,-1),-1代表自动计算维度\n",
    "        # 原因和解码器相同，因为torch预定义的GRU层只接受三维张量作为输入\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        # 然后使用relu函数对输出进行处理，根据relu函数的特性, 将使Embedding矩阵更稀疏，以防止过拟合\n",
    "        output = F.relu(output)\n",
    "        # 接下来, 将把embedding的输出以及初始化的hidden张量传入到解码器gru中\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # 因为GRU输出的output也是三维张量，第一维没有意义，因此可以通过output[0]来降维\n",
    "        # 再传给线性层做变换, 最后用softmax处理以便于分类\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        \"\"\"初始化隐层张量函数\"\"\"\n",
    "        # 将隐层张量初始化成为1x1xself.hidden_size大小的0张量\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:22:22.974067300Z",
     "start_time": "2024-07-27T02:22:22.964455Z"
    }
   },
   "id": "4591c3d78d536e20",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hidden_size = 25\n",
    "output_size = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:34:56.539692200Z",
     "start_time": "2024-07-27T02:34:56.515443200Z"
    }
   },
   "id": "dfe74872c18347ba",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input = pair_tensor[1][0]\n",
    "hidden = torch.zeros(1,1,hidden_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:34:56.988761700Z",
     "start_time": "2024-07-27T02:34:56.967609600Z"
    }
   },
   "id": "1522f794b20a4eab",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2706, -2.3249, -2.2158, -2.5419, -2.2787, -2.3876, -2.3750, -2.0713,\n",
      "         -2.3811, -2.2498]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "decoder = DecoderRNN(hidden_size,output_size)\n",
    "output,hidden = decoder(input,hidden)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:34:57.480975300Z",
     "start_time": "2024-07-27T02:34:57.440725400Z"
    }
   },
   "id": "7b82a950c32e4647",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        \"\"\"初始化函数中的参数有4个, hidden_size代表解码器中GRU的输入尺寸，也是它的隐层节点数\n",
    "           output_size代表整个解码器的输出尺寸, 也是我们希望得到的指定尺寸即目标语言的词表大小\n",
    "           dropout_p代表我们使用dropout层时的置零比率，默认0.1, max_length代表句子的最大长度\"\"\"\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        # 将以下参数传入类中\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # 实例化一个Embedding层, 输入参数是self.output_size和self.hidden_size\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        # 根据attention的QKV理论，attention的输入参数为三个Q，K，V，\n",
    "        # 第一步，使用Q与K进行attention权值计算得到权重矩阵, 再与V做矩阵乘法, 得到V的注意力表示结果.\n",
    "        # 这里常见的计算方式有三种:\n",
    "        # 1，将Q，K进行纵轴拼接, 做一次线性变化, 再使用softmax处理获得结果最后与V做张量乘法\n",
    "        # 2，将Q，K进行纵轴拼接, 做一次线性变化后再使用tanh函数激活, 然后再进行内部求和, 最后使用softmax处理获得结果再与V做张量乘法\n",
    "        # 3，将Q与K的转置做点积运算, 然后除以一个缩放系数, 再使用softmax处理获得结果最后与V做张量乘法\n",
    "\n",
    "        # 说明：当注意力权重矩阵和V都是三维张量且第一维代表为batch条数时, 则做bmm运算.\n",
    "\n",
    "        # 第二步, 根据第一步采用的计算方法, 如果是拼接方法，则需要将Q与第二步的计算结果再进行拼接, \n",
    "        # 如果是转置点积, 一般是自注意力, Q与V相同, 则不需要进行与Q的拼接.因此第二步的计算方式与第一步采用的全值计算方法有关.\n",
    "        # 第三步，最后为了使整个attention结构按照指定尺寸输出, 使用线性层作用在第二步的结果上做一个线性变换. 得到最终对Q的注意力表示.\n",
    "\n",
    "        # 我们这里使用的是第一步中的第一种计算方式, 因此需要一个线性变换的矩阵, 实例化nn.Linear\n",
    "        # 因为它的输入是Q，K的拼接, 所以输入的第一个参数是self.hidden_size * 2，第二个参数是self.max_length\n",
    "        # 这里的Q是解码器的Embedding层的输出, K是解码器GRU的隐层输出，因为首次隐层还没有任何输出，会使用编码器的隐层输出\n",
    "        # 而这里的V是编码器层的输出\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        # 接着我们实例化另外一个线性层, 它是attention理论中的第四步的线性层，用于规范输出尺寸\n",
    "        # 这里它的输入来自第三步的结果, 因为第三步的结果是将Q与第二步的结果进行拼接, 因此输入维度是self.hidden_size * 2\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        # 接着实例化一个nn.Dropout层，并传入self.dropout_p\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        # 之后实例化nn.GRU, 它的输入和隐层尺寸都是self.hidden_size\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        # 最后实例化gru后面的线性层，也就是我们的解码器输出层.\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \"\"\"forward函数的输入参数有三个, 分别是源数据输入张量, 初始的隐层张量, 以及解码器的输出张量\"\"\"\n",
    "\n",
    "        # 根据结构计算图, 输入张量进行Embedding层并扩展维度\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        # 使用dropout进行随机丢弃，防止过拟合\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        # 进行attention的权重计算, 哦我们呢使用第一种计算方式：\n",
    "        # 将Q，K进行纵轴拼接, 做一次线性变化, 最后使用softmax处理获得结果\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "\n",
    "        # 然后进行第一步的后半部分, 将得到的权重矩阵与V做矩阵乘法计算, 当二者都是三维张量且第一维代表为batch条数时, 则做bmm运算\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        # 之后进行第二步, 通过取[0]是用来降维, 根据第一步采用的计算方法, 需要将Q与第一步的计算结果再进行拼接\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "\n",
    "        # 最后是第三步, 使用线性层作用在第三步的结果上做一个线性变换并扩展维度，得到输出\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        # attention结构的结果使用relu激活\n",
    "        output = F.relu(output)\n",
    "\n",
    "        # 将激活后的结果作为gru的输入和hidden一起传入其中\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        # 最后将结果降维并使用softmax处理得到最终的结果\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        # 返回解码器结果，最后的隐层张量以及注意力权重张量\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        \"\"\"初始化隐层张量函数\"\"\"\n",
    "        # 将隐层张量初始化成为1x1xself.hidden_size大小的0张量\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:39:49.284521400Z",
     "start_time": "2024-07-27T02:39:49.252357700Z"
    }
   },
   "id": "9bf171033a1f42be",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hidden_size = 25\n",
    "output_size = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:39:58.004112Z",
     "start_time": "2024-07-27T02:39:57.980975100Z"
    }
   },
   "id": "3a190942c9643ed7",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input = pair_tensor[1][0]\n",
    "hidden = torch.zeros(1, 1, hidden_size)\n",
    "# encoder_outputs需要是encoder中每一个时间步的输出堆叠而成\n",
    "# 它的形状应该是10x25, 我们这里直接随机初始化一个张量\n",
    "encoder_outputs  = torch.randn(10, 25)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:40:03.163631300Z",
     "start_time": "2024-07-27T02:40:03.131526500Z"
    }
   },
   "id": "7e9960dd771a0e85",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3754, -2.2622, -2.2720, -2.5235, -2.2074, -2.3365, -2.2952, -2.3831,\n",
      "         -2.1830, -2.2325]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "decoder = AttnDecoderRNN(hidden_size, output_size)\n",
    "output, hidden, attn_weights= decoder(input, hidden, encoder_outputs)\n",
    "print(output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:40:08.069661900Z",
     "start_time": "2024-07-27T02:40:08.037245300Z"
    }
   },
   "id": "fb62df1798256079",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 设置teacher_forcing比率为0.5\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    \"\"\"训练函数, 输入参数有8个, 分别代表input_tensor：源语言输入张量，target_tensor：目标语言输入张量，encoder, decoder：编码器和解码器实例化对象\n",
    "       encoder_optimizer, decoder_optimizer：编码器和解码器优化方法，criterion：损失函数计算方法，max_length：句子的最大长度\"\"\"\n",
    "\n",
    "    # 初始化隐层张量\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    # 编码器和解码器优化器梯度归0\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # 根据源文本和目标文本张量获得对应的长度\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    # 初始化编码器输出张量，形状是max_lengthxencoder.hidden_size的0张量\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    # 初始设置损失为0\n",
    "    loss = 0\n",
    "\n",
    "    # 循环遍历输入张量索引\n",
    "    for ei in range(input_length):\n",
    "        # 根据索引从input_tensor取出对应的单词的张量表示，和初始化隐层张量一同传入encoder对象中\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        # 将每次获得的输出encoder_output(三维张量), 使用[0, 0]降两维变成向量依次存入到encoder_outputs\n",
    "        # 这样encoder_outputs每一行存的都是对应的句子中每个单词通过编码器的输出结果\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    # 初始化解码器的第一个输入，即起始符\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    # 初始化解码器的隐层张量即编码器的隐层输出\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # 根据随机数与teacher_forcing_ratio对比判断是否使用teacher_forcing\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # 如果使用teacher_forcing\n",
    "    if use_teacher_forcing:\n",
    "        # 循环遍历目标张量索引\n",
    "        for di in range(target_length):\n",
    "            # 将decoder_input, decoder_hidden, encoder_outputs即attention中的QKV, \n",
    "            # 传入解码器对象, 获得decoder_output, decoder_hidden, decoder_attention\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # 因为使用了teacher_forcing, 无论解码器输出的decoder_output是什么, 我们都只\n",
    "            # 使用‘正确的答案’，即target_tensor[di]来计算损失\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            # 并强制将下一次的解码器输入设置为‘正确的答案’\n",
    "            decoder_input = target_tensor[di]  \n",
    "\n",
    "    else:\n",
    "        # 如果不使用teacher_forcing\n",
    "        # 仍然遍历目标张量索引\n",
    "        for di in range(target_length):\n",
    "            # 将decoder_input, decoder_hidden, encoder_outputs传入解码器对象\n",
    "            # 获得decoder_output, decoder_hidden, decoder_attention\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # 只不过这里我们将从decoder_output取出答案\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            # 损失计算仍然使用decoder_output和target_tensor[di]\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            # 最后如果输出值是终止符，则循环停止\n",
    "            if topi.squeeze().item() == EOS_token:\n",
    "                break\n",
    "            # 否则，并对topi降维并分离赋值给decoder_input以便进行下次运算\n",
    "            # 这里的detach的分离作用使得这个decoder_input与模型构建的张量图无关，相当于全新的外界输入\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "\n",
    "    # 误差进行反向传播\n",
    "    loss.backward()\n",
    "    # 编码器和解码器进行优化即参数更新\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    # 最后返回平均损失\n",
    "    return loss.item() / target_length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:10.224622400Z",
     "start_time": "2024-07-27T02:42:10.177801600Z"
    }
   },
   "id": "c10dffb972cc8da1",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 导入时间和数学工具包\n",
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    \"获得每次打印的训练耗时, since是训练开始时间\"\n",
    "    # 获得当前时间\n",
    "    now = time.time()\n",
    "    # 获得时间差，就是训练耗时\n",
    "    s = now - since\n",
    "    # 将秒转化为分钟, 并取整\n",
    "    m = math.floor(s / 60)\n",
    "    # 计算剩下不够凑成1分钟的秒数\n",
    "    s -= m * 60\n",
    "    # 返回指定格式的耗时\n",
    "    return '%dm %ds' % (m, s)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:21.210010900Z",
     "start_time": "2024-07-27T02:42:21.171088400Z"
    }
   },
   "id": "8ea126767f4748fb",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 假定模型训练开始时间是10min之前\n",
    "since = time.time() - 10*60\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:29.791977900Z",
     "start_time": "2024-07-27T02:42:29.763897900Z"
    }
   },
   "id": "45a6bea39f083195",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m 9s\n"
     ]
    }
   ],
   "source": [
    "period = timeSince(since)\n",
    "print(period)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:38.991181700Z",
     "start_time": "2024-07-27T02:42:38.959848Z"
    }
   },
   "id": "8ed8adf68fb0c026",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 导入plt以便绘制损失曲线\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    \"\"\"训练迭代函数, 输入参数有6个，分别是encoder, decoder: 编码器和解码器对象，\n",
    "       n_iters: 总迭代步数, print_every:打印日志间隔, plot_every:绘制损失曲线间隔, learning_rate学习率\"\"\"\n",
    "    # 获得训练开始时间戳\n",
    "    start = time.time()\n",
    "    # 每个损失间隔的平均损失保存列表，用于绘制损失曲线\n",
    "    plot_losses = []\n",
    "\n",
    "    # 每个打印日志间隔的总损失，初始为0\n",
    "    print_loss_total = 0  \n",
    "    # 每个绘制损失间隔的总损失，初始为0\n",
    "    plot_loss_total = 0  \n",
    "\n",
    "    # 使用预定义的SGD作为优化器，将参数和学习率传入其中\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 选择损失函数\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # 根据设置迭代步进行循环\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        # 每次从语言对列表中随机取出一条作为训练语句\n",
    "        training_pair = tensorsFromPair(random.choice(pairs))\n",
    "        # 分别从training_pair中取出输入张量和目标张量\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        # 通过train函数获得模型运行的损失\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        # 将损失进行累和\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        # 当迭代步达到日志打印间隔时\n",
    "        if iter % print_every == 0:\n",
    "            # 通过总损失除以间隔得到平均损失\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            # 将总损失归0\n",
    "            print_loss_total = 0\n",
    "            # 打印日志，日志内容分别是：训练耗时，当前迭代步，当前进度百分比，当前平均损失\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        # 当迭代步达到损失绘制间隔时\n",
    "        if iter % plot_every == 0:\n",
    "            # 通过总损失除以间隔得到平均损失\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            # 将平均损失装进plot_losses列表\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            # 总损失归0\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    # 绘制损失曲线\n",
    "    plt.figure()  \n",
    "    plt.plot(plot_losses)\n",
    "    # 保存到指定路径\n",
    "    plt.savefig(\"./s2s_loss.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:43:11.138408100Z",
     "start_time": "2024-07-27T02:43:09.712290200Z"
    }
   },
   "id": "15d8adb81e8946b7",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 设置隐层大小为256 ，也是词嵌入维度      \n",
    "hidden_size = 256\n",
    "# 通过input_lang.n_words获取输入词汇总数，与hidden_size一同传入EncoderRNN类中\n",
    "# 得到编码器对象encoder1\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "\n",
    "# 通过output_lang.n_words获取目标词汇总数，与hidden_size和dropout_p一同传入AttnDecoderRNN类中\n",
    "# 得到解码器对象attn_decoder1\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "# 设置迭代步数 \n",
    "n_iters = 75000\n",
    "# 设置日志打印间隔\n",
    "print_every = 5000 \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T02:43:18.341823800Z",
     "start_time": "2024-07-27T02:43:18.299651800Z"
    }
   },
   "id": "e57086380ddbe52",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7m 33s (5000 6%) 3.4591\n",
      "15m 20s (10000 13%) 2.8213\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[60], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 调用trainIters进行模型训练，将编码器对象encoder1，码器对象attn_decoder1，迭代步数，日志打印间隔传入其中\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrainIters\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoder1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattn_decoder1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_iters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_every\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprint_every\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[58], line 33\u001B[0m, in \u001B[0;36mtrainIters\u001B[1;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001B[0m\n\u001B[0;32m     30\u001B[0m target_tensor \u001B[38;5;241m=\u001B[39m training_pair[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# 通过train函数获得模型运行的损失\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m             \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# 将损失进行累和\u001B[39;00m\n\u001B[0;32m     36\u001B[0m print_loss_total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n",
      "Cell \u001B[1;32mIn[54], line 79\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001B[0m\n\u001B[0;32m     75\u001B[0m         decoder_input \u001B[38;5;241m=\u001B[39m topi\u001B[38;5;241m.\u001B[39msqueeze()\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[0;32m     78\u001B[0m \u001B[38;5;66;03m# 误差进行反向传播\u001B[39;00m\n\u001B[1;32m---> 79\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;66;03m# 编码器和解码器进行优化即参数更新\u001B[39;00m\n\u001B[0;32m     81\u001B[0m encoder_optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32mC:\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[0;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[1;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 调用trainIters进行模型训练，将编码器对象encoder1，码器对象attn_decoder1，迭代步数，日志打印间隔传入其中\n",
    "trainIters(encoder1, attn_decoder1, n_iters, print_every=print_every)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T03:02:51.326894800Z",
     "start_time": "2024-07-27T02:43:24.690886Z"
    }
   },
   "id": "334363703cd39a4b",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    \"\"\"评估函数，输入参数有4个，分别是encoder, decoder: 编码器和解码器对象，\n",
    "       sentence:需要评估的句子，max_length:句子的最大长度\"\"\"\n",
    "\n",
    "    # 评估阶段不进行梯度计算\n",
    "    with torch.no_grad():\n",
    "        # 对输入的句子进行张量表示\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        # 获得输入的句子长度\n",
    "        input_length = input_tensor.size()[0]\n",
    "        # 初始化编码器隐层张量\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        # 初始化编码器输出张量，是max_lengthxencoder.hidden_size的0张量\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        # 循环遍历输入张量索引\n",
    "        for ei in range(input_length):\n",
    "             # 根据索引从input_tensor取出对应的单词的张量表示，和初始化隐层张量一同传入encoder对象中\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            #将每次获得的输出encoder_output(三维张量), 使用[0, 0]降两维变成向量依次存入到encoder_outputs\n",
    "            # 这样encoder_outputs每一行存的都是对应的句子中每个单词通过编码器的输出结果\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        # 初始化解码器的第一个输入，即起始符\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device) \n",
    "        # 初始化解码器的隐层张量即编码器的隐层输出\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # 初始化预测的词汇列表\n",
    "        decoded_words = []\n",
    "        # 初始化attention张量\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        # 开始循环解码\n",
    "        for di in range(max_length):\n",
    "            # 将decoder_input, decoder_hidden, encoder_outputs传入解码器对象\n",
    "            # 获得decoder_output, decoder_hidden, decoder_attention\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # 取所有的attention结果存入初始化的attention张量中\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            # 从解码器输出中获得概率最高的值及其索引对象\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            # 从索引对象中取出它的值与结束标志值作对比\n",
    "            if topi.item() == EOS_token:\n",
    "                # 如果是结束标志值，则将结束标志装进decoded_words列表，代表翻译结束\n",
    "                decoded_words.append('<EOS>')\n",
    "                # 循环退出\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # 否则，根据索引找到它在输出语言的index2word字典中对应的单词装进decoded_words\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            # 最后将本次预测的索引降维并分离赋值给decoder_input，以便下次进行预测\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        # 返回结果decoded_words， 以及完整注意力张量, 把没有用到的部分切掉\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-27T03:02:51.321338400Z"
    }
   },
   "id": "fe63b832c1931175"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=6):\n",
    "    \"\"\"随机测试函数, 输入参数encoder, decoder代表编码器和解码器对象，n代表测试数\"\"\"\n",
    "    # 对测试数进行循环\n",
    "    for i in range(n):\n",
    "        # 从pairs随机选择语言对\n",
    "        pair = random.choice(pairs)\n",
    "        # > 代表输入\n",
    "        print('>', pair[0])\n",
    "        # = 代表正确的输出\n",
    "        print('=', pair[1])\n",
    "        # 调用evaluate进行预测\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        # 将结果连成句子\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        # < 代表模型的输出\n",
    "        print('<', output_sentence)\n",
    "        print('')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-27T03:02:51.323537400Z"
    }
   },
   "id": "e0f2d9d6c7474053"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 调用evaluateRandomly进行模型测试，将编码器对象encoder1，码器对象attn_decoder1传入其中\n",
    "evaluateRandomly(encoder1, attn_decoder1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-27T03:02:51.324806900Z"
    }
   },
   "id": "a667fc6378b97f77"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sentence = \"we re both teachers .\"\n",
    "# 调用评估函数\n",
    "output_words, attentions = evaluate(\n",
    "encoder1, attn_decoder1, sentence)\n",
    "print(output_words)\n",
    "# 将attention张量转化成numpy, 使用matshow绘制\n",
    "plt.matshow(attentions.numpy())\n",
    "# 保存图像\n",
    "plt.savefig(\"./s2s_attn.png\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-27T03:02:51.331760900Z",
     "start_time": "2024-07-27T03:02:51.326894800Z"
    }
   },
   "id": "f4f9308656f78155"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6fabcf3a7ab2316f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
